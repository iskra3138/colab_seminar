{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MNIST Estimator_GPU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iskra3138/colab_seminar/blob/master/MNIST_Estimator_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N6ZDpd9XzFeN"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "KUu4vOt5zI9d",
        "colab": {}
      },
      "source": [
        "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgIge77Ca1xe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xqLjB2cy5S7m"
      },
      "source": [
        "## MNIST with the Estimator API\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RNo1Vfghpa8j"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook trains a model to classify images based on the handwritten numbers in the MNIST dataset. After training, the model classifies incoming images into\n",
        "10 categories (0 to 9) based on what it's learned from the dataset. \n",
        "\n",
        "This notebook uses Estimator on a GPU backend. It is a reference point for converting an Estimator model to TPUEstimator and a TPU backend. This conversion is demonstrated in the [TPUEstimator](https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/mnist_tpuestimator.ipynb) notebook. The conversion enables your model to take advantage of Cloud TPU to speed up training computations.\n",
        "\n",
        "This notebook is hosted on GitHub. To view it in its original repository, after opening the notebook, select **File > View on GitHub**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MmJgAdAYyWZ-"
      },
      "source": [
        "## Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_I0RdnOSkNmi"
      },
      "source": [
        "<h3><a href=\"https://cloud.google.com/gpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/gpu-hexagon.png\" width=\"50\"></a>  &nbsp;&nbsp;Train on GPU</a></h3>\n",
        "\n",
        "  1. Create a Cloud Storage bucket for your TensorBoard logs at http://console.cloud.google.com/storage and fill in the BUCKET parameter in the \"Parameters\" section below.\n",
        "  1. On the main menu, click Runtime and select **Change runtime type**. Set \"GPU\" as the hardware accelerator.\n",
        "  1. Click Runtime again and select **Runtime > Run All** (Watch out: the \"Colab-only auth\" cell requires user input). You can also run the cells manually with Shift-ENTER.\n",
        "\n",
        "<h3><a href=\"https://cloud.google.com/ml-engine/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/mlengine-hexagon.png\" width=\"50\"></a>  &nbsp;&nbsp;Deploy to Cloud Machine Learning (ML) Engine</h3>\n",
        "1. At the bottom of this notebook you can deploy your trained model to ML Engine for a serverless, autoscaled, REST API experience. You will need a GCP project name for this last part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lvo0t7XVIkWZ"
      },
      "source": [
        "## Data, model, and training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qpiJj8ym0v0-"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AoilhmYe1b5t",
        "colab": {}
      },
      "source": [
        "import os, re, math, json, shutil, pprint, datetime\n",
        "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.python.platform import tf_logging\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aBDGQWkbLGvh"
      },
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_V_VbLELLJCS",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32 #@param {type:\"integer\"}\n",
        "BUCKET = 'gs://' #@param {type:\"string\"}\n",
        "\n",
        "assert re.search(r'gs://.+', BUCKET), 'You need a GCS bucket for your Tensorboard logs. Head to http://console.cloud.google.com/storage and create one.'\n",
        "\n",
        "training_images_file   = 'gs://mnist-public/train-images-idx3-ubyte'\n",
        "training_labels_file   = 'gs://mnist-public/train-labels-idx1-ubyte'\n",
        "validation_images_file = 'gs://mnist-public/t10k-images-idx3-ubyte'\n",
        "validation_labels_file = 'gs://mnist-public/t10k-labels-idx1-ubyte'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lzd6Qi464PsA"
      },
      "source": [
        "### Colab-only auth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "MPx0nvyUnvgT",
        "colab": {}
      },
      "source": [
        "# backend identification\n",
        "IS_COLAB_BACKEND = 'COLAB_GPU' in os.environ  # this is always set on Colab, the value is 0 or 1 depending on GPU presence\n",
        "\n",
        "# Auth on Colab\n",
        "# Little wrinkle: without auth, Colab will be extremely slow in accessing data from a GCS bucket, even public\n",
        "if IS_COLAB_BACKEND:\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFuNPiEyVNDw",
        "colab_type": "text"
      },
      "source": [
        "## GCP내에 storage bucket 생성하기\n",
        "새로 추가한 코드임"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tUvyGy8VMDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# project ID 확인\n",
        "!gcloud projects list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49Pj57xnWyFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PROJECT = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWi95axuV8XD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# bucket 생성\n",
        "### !gsutil mb -p {PROJECT_NUMBER} {BUCKET_NAME}\n",
        "!gsutil mb -p  {PROJECT} {BUCKET}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpalJoohWT3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# bucket 목록 확인\n",
        "!gsutil ls -p {PROJECT}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCILuRBpbhOS",
        "colab_type": "text"
      },
      "source": [
        "dataset api가 Tensorflow version update 되면서 수정이 생긴것 같음.</br> \n",
        "아래 visualization utilites중 dataset_to_numpy_util함수는 수정해야지만 돌아감"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "qhdz68Xm3Z4Z",
        "colab": {}
      },
      "source": [
        "#@title visualization utilities [RUN ME]\n",
        "\"\"\"\n",
        "This cell contains helper functions used for visualization\n",
        "and downloads only. You can skip reading it. There is very\n",
        "little useful Keras/Tensorflow code here.\n",
        "\"\"\"\n",
        "\n",
        "# Matplotlib config\n",
        "plt.rc('image', cmap='gray_r')\n",
        "plt.rc('grid', linewidth=0)\n",
        "plt.rc('xtick', top=False, bottom=False, labelsize='large')\n",
        "plt.rc('ytick', left=False, right=False, labelsize='large')\n",
        "plt.rc('axes', facecolor='F8F8F8', titlesize=\"large\", edgecolor='white')\n",
        "plt.rc('text', color='a8151a')\n",
        "plt.rc('figure', facecolor='F0F0F0')# Matplotlib fonts\n",
        "MATPLOTLIB_FONT_DIR = os.path.join(os.path.dirname(plt.__file__), \"mpl-data/fonts/ttf\")\n",
        "\n",
        "# pull a batch from the datasets. This code is not very nice, it gets much better in eager mode (TODO)\n",
        "def dataset_to_numpy_util(training_dataset, validation_dataset, N):\n",
        "  \n",
        "  # get one batch from each: 10000 validation digits, N training digits\n",
        "  unbatched_train_ds = training_dataset.unbatch()\n",
        "  ######################################## 원래코드 ##################################################\n",
        "  ###v_images, v_labels = validation_dataset.make_one_shot_iterator().get_next()\n",
        "  ###t_images, t_labels = unbatched_train_ds.batch(N).make_one_shot_iterator().get_next()\n",
        "  ######################################## 수정코드 ##################################################\n",
        "  v_images, v_labels = tf.compat.v1.data.make_one_shot_iterator(validation_dataset).get_next()\n",
        "  t_images, t_labels = tf.compat.v1.data.make_one_shot_iterator(unbatched_train_ds.batch(N)).get_next()\n",
        "  \n",
        "  # Run once, get one batch. Session.run returns numpy results\n",
        "  with tf.Session() as ses:\n",
        "    (validation_digits, validation_labels,\n",
        "     training_digits, training_labels) = ses.run([v_images, v_labels, t_images, t_labels])\n",
        "  \n",
        "  # these were one-hot encoded in the dataset\n",
        "  validation_labels = np.argmax(validation_labels, axis=1)\n",
        "  training_labels = np.argmax(training_labels, axis=1)\n",
        "  \n",
        "  return (training_digits, training_labels,\n",
        "          validation_digits, validation_labels)\n",
        "\n",
        "# create digits from local fonts for testing\n",
        "def create_digits_from_local_fonts(n):\n",
        "  font_labels = []\n",
        "  img = PIL.Image.new('LA', (28*n, 28), color = (0,255)) # format 'LA': black in channel 0, alpha in channel 1\n",
        "  font1 = PIL.ImageFont.truetype(os.path.join(MATPLOTLIB_FONT_DIR, 'DejaVuSansMono-Oblique.ttf'), 25)\n",
        "  font2 = PIL.ImageFont.truetype(os.path.join(MATPLOTLIB_FONT_DIR, 'STIXGeneral.ttf'), 25)\n",
        "  d = PIL.ImageDraw.Draw(img)\n",
        "  for i in range(n):\n",
        "    font_labels.append(i%10)\n",
        "    d.text((7+i*28,0 if i<10 else -4), str(i%10), fill=(255,255), font=font1 if i<10 else font2)\n",
        "  font_digits = np.array(img.getdata(), np.float32)[:,0] / 255.0 # black in channel 0, alpha in channel 1 (discarded)\n",
        "  font_digits = np.reshape(np.stack(np.split(np.reshape(font_digits, [28, 28*n]), n, axis=1), axis=0), [n, 28*28])\n",
        "  return font_digits, font_labels\n",
        "\n",
        "# utility to display a row of digits with their predictions\n",
        "def display_digits(digits, predictions, labels, title, n):\n",
        "  plt.figure(figsize=(13,3))\n",
        "  digits = np.reshape(digits, [n, 28, 28])\n",
        "  digits = np.swapaxes(digits, 0, 1)\n",
        "  digits = np.reshape(digits, [28, 28*n])\n",
        "  plt.yticks([])\n",
        "  plt.xticks([28*x+14 for x in range(n)], predictions)\n",
        "  for i,t in enumerate(plt.gca().xaxis.get_ticklabels()):\n",
        "    if predictions[i] != labels[i]: t.set_color('red') # bad predictions in red\n",
        "  plt.imshow(digits)\n",
        "  plt.grid(None)\n",
        "  plt.title(title)\n",
        "  \n",
        "# utility to display multiple rows of digits, sorted by unrecognized/recognized status\n",
        "def display_top_unrecognized(digits, predictions, labels, n, lines):\n",
        "  idx = np.argsort(predictions==labels) # sort order: unrecognized first\n",
        "  for i in range(lines):\n",
        "    display_digits(digits[idx][i*n:(i+1)*n], predictions[idx][i*n:(i+1)*n], labels[idx][i*n:(i+1)*n],\n",
        "                   \"{} sample validation digits out of {} with bad predictions in red and sorted first\".format(n*lines, len(digits)) if i==0 else \"\", n)\n",
        "    \n",
        "# utility to display training and validation curves\n",
        "def display_training_curves(training, validation, title, subplot):\n",
        "  if subplot%10==1: # set up the subplots on the first call\n",
        "    plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n",
        "    plt.tight_layout()\n",
        "  ax = plt.subplot(subplot)\n",
        "  ax.grid(linewidth=1, color='white')\n",
        "  ax.plot(training)\n",
        "  ax.plot(validation)\n",
        "  ax.set_title('model '+ title)\n",
        "  ax.set_ylabel(title)\n",
        "  ax.set_xlabel('epoch')\n",
        "  ax.legend(['train', 'valid.'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lz1Zknfk4qCx"
      },
      "source": [
        "### tf.data.Dataset: parse files and prepare training and validation datasets\n",
        "Please read the [best practices for building](https://www.tensorflow.org/guide/performance/datasets) input pipelines with tf.data.Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZE8dgyPC1_6m",
        "colab": {}
      },
      "source": [
        "def read_label(tf_bytestring):\n",
        "    label = tf.decode_raw(tf_bytestring, tf.uint8)\n",
        "    label = tf.reshape(label, [])\n",
        "    label = tf.one_hot(label, 10)\n",
        "    return label\n",
        "  \n",
        "def read_image(tf_bytestring):\n",
        "    image = tf.decode_raw(tf_bytestring, tf.uint8)\n",
        "    image = tf.cast(image, tf.float32)/255.0\n",
        "    image = tf.reshape(image, [28*28])\n",
        "    return image\n",
        "  \n",
        "def load_dataset(image_file, label_file):\n",
        "    imagedataset = tf.data.FixedLengthRecordDataset(image_file, 28*28, header_bytes=16)\n",
        "    imagedataset = imagedataset.map(read_image, num_parallel_calls=16)\n",
        "    labelsdataset = tf.data.FixedLengthRecordDataset(label_file, 1, header_bytes=8)\n",
        "    labelsdataset = labelsdataset.map(read_label, num_parallel_calls=16)\n",
        "    dataset = tf.data.Dataset.zip((imagedataset, labelsdataset))\n",
        "    return dataset \n",
        "  \n",
        "def get_training_dataset(image_file, label_file, batch_size):\n",
        "    dataset = load_dataset(image_file, label_file)\n",
        "    dataset = dataset.cache()  # this small dataset can be entirely cached in RAM, for TPU this is important to get good performance from such a small dataset\n",
        "    dataset = dataset.shuffle(5000, reshuffle_each_iteration=True)\n",
        "    dataset = dataset.repeat() # Mandatory for Keras for now\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True) # drop_remainder is important on TPU, batch size must be fixed\n",
        "    dataset = dataset.prefetch(10)  # fetch next batches while training on the current one\n",
        "    return dataset\n",
        "  \n",
        "def get_validation_dataset(image_file, label_file):\n",
        "    dataset = load_dataset(image_file, label_file)\n",
        "    dataset = dataset.cache() # this small dataset can be entirely cached in RAM, for TPU this is important to get good performance from such a small dataset\n",
        "    dataset = dataset.batch(10000, drop_remainder=True) # 10000 items in eval dataset, all in one batch\n",
        "    dataset = dataset.repeat() # Mandatory for Keras for now\n",
        "    return dataset\n",
        "\n",
        "# instantiate the datasets\n",
        "training_dataset = get_training_dataset(training_images_file, training_labels_file, BATCH_SIZE)\n",
        "validation_dataset = get_validation_dataset(validation_images_file, validation_labels_file)\n",
        "\n",
        "# In Estimator, we will need a function that returns the dataset\n",
        "training_input_fn = lambda: get_training_dataset(training_images_file, training_labels_file, BATCH_SIZE)\n",
        "validation_input_fn = lambda: get_validation_dataset(validation_images_file, validation_labels_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_fXo6GuvL3EB"
      },
      "source": [
        "### Let's have a look at the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DaWNgUPKLz_9",
        "colab": {}
      },
      "source": [
        "N = 24\n",
        "(training_digits, training_labels,\n",
        " validation_digits, validation_labels) = dataset_to_numpy_util(training_dataset, validation_dataset, N)\n",
        "display_digits(training_digits, training_labels, training_labels, \"training digits and their labels\", N)\n",
        "display_digits(validation_digits[:N], validation_labels[:N], validation_labels[:N], \"validation digits and their labels\", N)\n",
        "font_digits, font_labels = create_digits_from_local_fonts(N)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KIc0oqiD40HC"
      },
      "source": [
        "### Estimator model\n",
        "If you are not sure what cross-entropy, dropout, softmax or batch-normalization mean, head here for a crash-course: [Tensorflow and deep learning without a PhD](https://github.com/GoogleCloudPlatform/tensorflow-without-a-phd/#featured-code-sample)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "56y8UNFQIVwj",
        "colab": {}
      },
      "source": [
        "# This model trains to 99.4% sometimes 99.5% accuracy in 10 epochs\n",
        "def model_fn(features, labels, mode):\n",
        "  x = features\n",
        "  \n",
        "  is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "  x = features\n",
        "  y = tf.reshape(x, [-1, 28, 28, 1])\n",
        "\n",
        "  # little wrinkle: tf.keras.layers can normally be used in an Estimator but tf.keras.layers.BatchNormalization does not work\n",
        "  # in an Estimator environment. Using TF layers everywhere for consistency. tf.layers and tf.ketas.layers are carbon copies of each other.\n",
        "  \n",
        "  y = tf.layers.Conv2D(filters=6, kernel_size=3, padding='same', use_bias=False)(y) # no bias necessary before batch norm\n",
        "  y = tf.layers.BatchNormalization(scale=False, center=True)(y, training=is_training) # no batch norm scaling necessary before \"relu\"\n",
        "  y = tf.nn.relu(y) # activation after batch norm\n",
        "\n",
        "  y = tf.layers.Conv2D(filters=12, kernel_size=6, padding='same', use_bias=False, strides=2)(y)\n",
        "  y = tf.layers.BatchNormalization(scale=False, center=True)(y, training=is_training)\n",
        "  y = tf.nn.relu(y)\n",
        "\n",
        "  y = tf.layers.Conv2D(filters=24, kernel_size=6, padding='same', use_bias=False, strides=2)(y)\n",
        "  y = tf.layers.BatchNormalization(scale=False, center=True)(y, training=is_training)\n",
        "  y = tf.nn.relu(y)\n",
        "\n",
        "  y = tf.layers.Flatten()(y)\n",
        "  y = tf.layers.Dense(200, use_bias=False)(y)\n",
        "  y = tf.layers.BatchNormalization(scale=False, center=True)(y, training=is_training)\n",
        "  y = tf.nn.relu(y)\n",
        "  y = tf.layers.Dropout(0.5)(y, training=is_training)\n",
        "  \n",
        "  logits = tf.layers.Dense(10)(y)\n",
        "  predictions = tf.nn.softmax(logits)\n",
        "  classes = tf.math.argmax(predictions, axis=-1)\n",
        "  \n",
        "  if (mode != tf.estimator.ModeKeys.PREDICT):\n",
        "    loss = tf.losses.softmax_cross_entropy(labels, logits)\n",
        "\n",
        "    step = tf.train.get_or_create_global_step()\n",
        "    lr = 0.0001 + tf.train.exponential_decay(0.01, step, 2000, 1/math.e)\n",
        "    tf.summary.scalar(\"learn_rate\", lr)\n",
        "\n",
        "    optimizer = tf.train.AdamOptimizer(lr)\n",
        "    # little wrinkle: batch norm uses running averages which need updating after each batch. create_train_op does it, optimizer.minimize does not.\n",
        "    train_op = tf.contrib.training.create_train_op(loss, optimizer)\n",
        "    #train_op = optimizer.minimize(loss, tf.train.get_or_create_global_step())\n",
        "\n",
        "    metrics = {'accuracy': tf.metrics.accuracy(classes, tf.math.argmax(labels, axis=-1))}\n",
        "  else:\n",
        "    loss = train_op = metrics = None  # None of these can be computed in prediction mode because labels are not available\n",
        "  \n",
        "  return tf.estimator.EstimatorSpec(\n",
        "    mode=mode,\n",
        "    predictions={\"predictions\": predictions, \"classes\": classes},  # name these fields as you like\n",
        "    loss=loss,\n",
        "    train_op=train_op,\n",
        "    eval_metric_ops=metrics\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DeIxkrv9Wihg",
        "colab": {}
      },
      "source": [
        "# Called once when the model is saved. This function produces a Tensorflow\n",
        "# graph of operations that will be prepended to your model graph. When\n",
        "# your model is deployed as a REST API, the API receives data in JSON format,\n",
        "# parses it into Tensors, then sends the tensors to the input graph generated by\n",
        "# this function. The graph can transform the data so it can be sent into your\n",
        "# model input_fn. You can do anything you want here as long as you do it with\n",
        "# tf.* functions that produce a graph of operations.\n",
        "def serving_input_fn():\n",
        "    # placeholder for the data received by the API (already parsed, no JSON decoding necessary,\n",
        "    # but the JSON must contain one or multiple 'image' key(s) with 28x28 greyscale images  as content.)\n",
        "    inputs = {\"serving_input\": tf.placeholder(tf.float32, [None, 28, 28])}  # the shape of this dict should match the shape of your JSON\n",
        "    features = inputs['serving_input']  # no transformation needed\n",
        "    return tf.estimator.export.TensorServingInputReceiver(features, inputs)  # features are the features needed by your model_fn\n",
        "    # Return a ServingInputReceiver if your features are a dictionary of Tensors, TensorServingInputReceiver if they are a straight Tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RxpRgF874-ix"
      },
      "source": [
        "### Train and validate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TTwH_P-ZJ_xx",
        "colab": {}
      },
      "source": [
        "EPOCHS = 8\n",
        "steps_per_epoch = 60000 // BATCH_SIZE  # 60,000 images in training dataset\n",
        "MODEL_EXPORT_NAME = \"mnist\"  # name for exporting saved model\n",
        "\n",
        "tf_logging.set_verbosity(tf_logging.INFO)\n",
        "now = datetime.datetime.now()\n",
        "MODEL_DIR = BUCKET+\"/mnistjobs/job\" + \"-{}-{:02d}-{:02d}-{:02d}:{:02d}:{:02d}\".format(now.year, now.month, now.day, now.hour, now.minute, now.second)\n",
        "\n",
        "training_config = tf.estimator.RunConfig(model_dir=MODEL_DIR, save_summary_steps=10, save_checkpoints_steps=steps_per_epoch, log_step_count_steps=steps_per_epoch/4)\n",
        "export_latest = tf.estimator.LatestExporter(MODEL_EXPORT_NAME, serving_input_receiver_fn=serving_input_fn)\n",
        "estimator = tf.estimator.Estimator(model_fn=model_fn, config=training_config)\n",
        "\n",
        "train_spec = tf.estimator.TrainSpec(training_input_fn, max_steps=EPOCHS*steps_per_epoch)\n",
        "eval_spec = tf.estimator.EvalSpec(validation_input_fn, steps=1, exporters=export_latest, throttle_secs=0) # no eval throttling: evaluates after each checkpoint\n",
        "\n",
        "tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
        "tf_logging.set_verbosity(tf_logging.WARN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9jFVovcUUVs1"
      },
      "source": [
        "### Visualize predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w12OId8Mz7dF",
        "colab": {}
      },
      "source": [
        "# recognize digits from local fonts\n",
        "predictions = estimator.predict(lambda:  tf.data.Dataset.from_tensor_slices(font_digits).batch(N),\n",
        "                                  yield_single_examples=False)  # the returned value is a generator that will yield one batch of predictions per next() call\n",
        "predicted_font_classes = next(predictions)['classes']\n",
        "display_digits(font_digits, predicted_font_classes, font_labels, \"predictions from local fonts (bad predictions in red)\", N)\n",
        "\n",
        "# recognize validation digits\n",
        "predictions = estimator.predict(validation_input_fn,\n",
        "                                    yield_single_examples=False)  # the returned value is a generator that will yield one batch of predictions per next() call\n",
        "predicted_labels = next(predictions)['classes']\n",
        "display_top_unrecognized(validation_digits, predicted_labels, validation_labels, N, 7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYPULCcEr4Fx",
        "colab_type": "text"
      },
      "source": [
        "## Tensorboard 실행 추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJYD5Lwrp2t6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_DIR =BUCKET+\"/mnistjobs/job\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YpNsZWzqTwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ87YEVwq3sG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwTo_d2trCNO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX2BcGQ-rHWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5tzVi39ShrEL"
      },
      "source": [
        "## Deploy the trained model to ML Engine\n",
        "\n",
        "Push your trained model to production on ML Engine for a serverless, autoscaled, REST API experience.\n",
        "\n",
        "You need the name of your GCS bucket and GCP project for this step. Models deployed on ML Engine autoscale to zero if not used. There will be no ML Engine charges after you are done testing.\n",
        "Google Cloud Storage incurs charges. Empty the bucket after deployment if you want to avoid these. Once the model is deployed, the bucket is not useful anymore."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3Y3ztMY_toCP"
      },
      "source": [
        "### Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "VoN13WTwtPVp",
        "colab": {}
      },
      "source": [
        "#PROJECT = \"\" #@param {type:\"string\"}\n",
        "NEW_MODEL = True #@param {type:\"boolean\"}\n",
        "MODEL_NAME = \"estimator_mnist\" #@param {type:\"string\"}\n",
        "MODEL_VERSION = \"v0\" #@param {type:\"string\"}\n",
        "\n",
        "assert PROJECT, 'For this part, you need a GCP project. Head to http://console.cloud.google.com/ and create one.'\n",
        "\n",
        "export_path = os.path.join(MODEL_DIR, 'export', MODEL_EXPORT_NAME)\n",
        "last_export = sorted(tf.gfile.ListDirectory(export_path))[-1]\n",
        "export_path = os.path.join(export_path, last_export)\n",
        "print('Saved model directory found: ', export_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zy3T3zk0u2J0"
      },
      "source": [
        "### Deploy the model\n",
        "This uses the command-line interface. You can do the same thing through the ML Engine UI at https://console.cloud.google.com/mlengine/models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nGv3ITiGLPL3",
        "colab": {}
      },
      "source": [
        "# Create the model\n",
        "if NEW_MODEL:\n",
        "  #!gcloud ml-engine models create {MODEL_NAME} --project={PROJECT} --regions=us-central1\n",
        "  !gcloud ai-platform models create {MODEL_NAME} --project={PROJECT} --regions=us-central1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-jqrNK2hTQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o3QtUowtOAL-",
        "colab": {}
      },
      "source": [
        "# Create a version of this model (you can add --async at the end of the line to make this call non blocking)\n",
        "# Additional config flags are available: https://cloud.google.com/ml-engine/reference/rest/v1/projects.models.versions\n",
        "# You can also deploy a model that is stored locally by providing a --staging-bucket=... parameter\n",
        "!echo \"Deployment takes a couple of minutes. You can watch your deployment here: https://console.cloud.google.com/mlengine/models/{MODEL_NAME}\"\n",
        "#!gcloud ml-engine versions create {MODEL_VERSION} --model={MODEL_NAME} --origin={export_path} --project={PROJECT} --runtime-version=1.10\n",
        "\n",
        "### 1.10이라 하면 TF version 안 맞아서 생기는 문제 발생\n",
        "TF_VER = \"1.15\"\n",
        "!gcloud ai-platform versions create {MODEL_VERSION} --model={MODEL_NAME} --origin={export_path} --project={PROJECT} --runtime-version={TF_VER} --python-version=3.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jE-k1Zn6kU2Z"
      },
      "source": [
        "### Test the deployed model\n",
        "Your model is now available as a REST API. Let us try to call it. The cells below use the \"gcloud ml-engine\"\n",
        "command line tool but any tool that can send a JSON payload to a REST endpoint will work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zZCt0Ke2QDer",
        "colab": {}
      },
      "source": [
        "# prepare digits to send to online prediction endpoint\n",
        "digits = np.concatenate((font_digits, validation_digits[:100-N]))\n",
        "labels = np.concatenate((font_labels, validation_labels[:100-N]))\n",
        "with open(\"digits.json\", \"w\") as f:\n",
        "  for digit in digits:\n",
        "    # the format for ML Engine online predictions is: one JSON object per line\n",
        "    data = json.dumps({\"serving_input\": digit.tolist()})  # \"serving_input\" because that is what you defined in your serving_input_fn: {\"serving_input\": tf.placeholder(tf.float32, [None, 28, 28])}\n",
        "    f.write(data+'\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0oArdipg96H",
        "colab_type": "text"
      },
      "source": [
        "원래 코드인 예전 API ml-engine를 쓰면 prdeictions에 안내 메세지가 함께 들어가버려 실제 추론시 에러 발생</br>\n",
        "\"'\\x1b[1;33mWARNING:\\x1b[0m The `gcloud ml-engine` commands have been renamed and will soon be removed. Please use `gcloud ai-platform` instead.'이 'CLASSES  PREDICTIONS 에 들어가 버림\"</br>\n",
        "ai-platform API로 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n6PqhQ8RQ8bp",
        "colab": {}
      },
      "source": [
        "# Request online predictions from deployed model (REST API) using the \"gcloud ml-engine\" command line.\n",
        "#predictions = !gcloud ml-engine predict --model={MODEL_NAME} --json-instances digits.json --project={PROJECT} --version {MODEL_VERSION}\n",
        "\n",
        "predictions = !gcloud ai-platform predict --model={MODEL_NAME} --json-instances digits.json --project={PROJECT} --version {MODEL_VERSION}\n",
        "\n",
        "predictions = np.array([int(p.split('[')[0]) for p in predictions[1:]]) # first line is the name of the input layer: drop it, parse the rest\n",
        "display_top_unrecognized(digits, predictions, labels, N, 100//N)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2a5cGsSTEBQD"
      },
      "source": [
        "## What's next\n",
        "\n",
        "* Learn how to convert an [estimator model to a TPUEstimator model](https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/mnist_tpuestimator.ipynb) to take advantage of [Cloud TPUs](https://cloud.google.com/tpu/docs).\n",
        "* Explore the range of [Cloud TPU tutorials and Colabs](https://cloud.google.com/tpu/docs/tutorials) to find other examples that can be used when implementing your ML project.\n",
        "\n",
        "On Google Cloud Platform, in addition to GPUs and TPUs available on pre-configured [deep learning VMs](https://cloud.google.com/deep-learning-vm/),  you will find [AutoML](https://cloud.google.com/automl/)*(beta)* for training custom models without writing code and [Cloud ML Engine](https://cloud.google.com/ml-engine/docs/) which will allows you to run parallel trainings and hyperparameter tuning of your custom models on powerful distributed hardware.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XXSk0bENYB7-"
      },
      "source": [
        "## License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hleIN5-pcr0N"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "author: Martin Gorner<br>\n",
        "twitter: @martin_gorner\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Copyright 2018 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This is not an official Google product but sample code provided for an educational purpose\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IExkVKbptZL",
        "colab_type": "text"
      },
      "source": [
        "# 작업했던 bucket과 생성된 model을 삭제하는 코드 (추가됨)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dndamZ7Pp02j",
        "colab_type": "text"
      },
      "source": [
        "## bucket 삭제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FInlnzW7rmDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# bucket 목록 확인\n",
        "!gsutil ls -p {PROJECT}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxKi5BXWqNue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gsutil rm -r {BUCKET} "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfgEvBL_rI8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# bucket 삭제됨을 확인\n",
        "!gsutil ls -p {PROJECT}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEiPfZWbq3QN",
        "colab_type": "text"
      },
      "source": [
        "### model 삭제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPZJCI9DmUTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model list 보기\n",
        "!gcloud ai-platform models list --project={PROJECT}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9l-2EDFor4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# version 부터 삭제\n",
        "!gcloud ai-platform versions delete {MODEL_VERSION} --model={MODEL_NAME} --project={PROJECT}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGMreqNjnSJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model list로 version 삭제 확인\n",
        "!gcloud ai-platform models list --project={PROJECT}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sktSXhLnlm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model 삭제\n",
        "!gcloud ai-platform models delete {MODEL_NAME} --project={PROJECT}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ResgQLMCnok6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model 삭제 확인\n",
        "!gcloud ai-platform models list --project={PROJECT}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8Q_7UJZhwD_",
        "colab_type": "text"
      },
      "source": [
        "## Clean Up\n",
        "Before running the next exercise, run the following cell to terminate the kernel and free memory resources:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X0zL0j-hxy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, signal\n",
        "#os.kill(os.getpid(), signal.SIGKILL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw-c9L2NOx7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}