{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5. tpu 소개.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOQzneLpGJx9IycWVOYVaN4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iskra3138/colab_seminar/blob/master/5_tpu_%EC%86%8C%EA%B0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTU5u29mtN8s",
        "colab_type": "text"
      },
      "source": [
        "# TPU\n",
        "\n",
        "- Tensor Processing Unit(TPU)은 Google에서 맞춤 개발한 ASIC(Application-Specific Integrated Circuit)\n",
        "- Cloud TPU 종류는 다음과 같으며, 지역에 따라 사용할 수 있는 종류가 다름\n",
        "\n",
        "\n",
        "| TPU 유형(v2)|\tTPU v2 코어 |\t총 TPU 메모리\t|\n",
        "| :---------- | :---------: | ------------: |\n",
        "| v2-8\t| 8\t| 64GiB\t|\n",
        "|v2-32(베타)\t|32\t|256GiB\t|\n",
        "|v2-128(베타)\t|128\t|1TiB\t|\n",
        "|v2-256(베타)\t|256\t|2TiB\t|\n",
        "|v2-512(베타)\t|512\t|4TiB\t|\n",
        "\n",
        "</br>\n",
        "\n",
        "|TPU 유형(v3)\t|TPU v3 코어\t|총 TPU 메모리\t|\n",
        "| :---------- | :---------: | ------------: |\n",
        "|v3-8\t|8\t|128GiB\t|\n",
        "v3-32(베타)|\t32|\t512GiB|\n",
        "v3-64(베타)|\t64|\t1TiB|\n",
        "v3-128(베타)|\t128|\t2TiB|\n",
        "v3-256(베타)|\t256|\t4TiB|\n",
        "v3-512(베타)|\t512|\t8TiB|\n",
        "v3-1024(베타)|\t1024|\t16TiB|\n",
        "v3-2048(베타)|\t2048|\t32TiB|\n",
        "\n",
        "|TPU v2\t|TPU v3\t|\n",
        "| :---------- | :---------: |\n",
        "|Cloud TPU v2 : 180테라플롬 64GB 메모리</br>![Cloud TPU v2](https://cloud.google.com/images/products/tpu/cloud-tpu-v2.png?hl=ko) |Cloud TPU v3 : 420테라플롬 128GB 메모리</br>![Cloud TPU v3](https://cloud.google.com/images/products/tpu/cloud-tpu-v3-img.png?hl=ko)|\n",
        "|Cloud TPU v2 Pod: 11.5페타플롭 4TB 메모리</br>![Cloud TPU v2 Pod](https://cloud.google.com/images/products/tpu/cloud-tpu-v2-pod-alpha.png?hl=ko) |Cloud TPU v3 Pod: 100페타플롭 이상 32TB 메모리</br>![Cloud TPU v3 Pod](https://cloud.google.com/images/products/tpu/cloud-tpu-v3-pod-beta.png?hl=ko)|\n",
        "\n",
        "[출처] <https://cloud.google.com/tpu/docs/tpus?hl=ko>, <https://cloud.google.com/tpu/?hl=ko?>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_uNjwLLs_-Y",
        "colab_type": "text"
      },
      "source": [
        "# CPU, GPU, TPU 작동원리\n",
        "\n",
        "\n",
        "\n",
        "- 아래 그림과 같이 숫자 필기 이미지를 인식하는 Full connected 단일 레이어 신경망을 예시로 설명\n",
        "![대체 텍스트](https://cloud.google.com/tpu/docs/images/image8_qnuvyd4.png?hl=ko)\n",
        "</br></br></br>\n",
        "- 문제를 단순화하여 9개의 픽셀값이 인풋으로 들어와 각각의 아웃풋 연산을 위한 9개의 weight들과 곱셉연산이 일어나는 것만 보겠음\n",
        "![대체 텍스트](https://cloud.google.com/tpu/docs/images/image3_aovcb32.gif?hl=ko)\n",
        "\n",
        "\n",
        "[출처] <https://cloud.google.com/tpu/docs/beginners-guide?hl=ko>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkgM-kptxLNz",
        "colab_type": "text"
      },
      "source": [
        "### CPU 작동원리\n",
        "\n",
        "-  CPU의 산술 논리 장치(ALU)는 승산기와 가산기를 보유하고 제어하는 구성요소로서 한 번에 하나의 계산만 실행\n",
        "\n",
        "![대체 텍스트](https://cloud.google.com/tpu/docs/images/image6.gif?hl=ko)\n",
        "\n",
        "*참고: 이 애니메이션은 개념 제시용이며 실제 프로세서 동작을 반영하지 않습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ETqmBXLxPho",
        "colab_type": "text"
      },
      "source": [
        "### GPU 작동원리\n",
        "\n",
        "- GPU는 CPU보다 높은 처리량을 얻기 위해 단일 프로세서에 수천 개의 ALU를 배치\n",
        "- 최신형 GPU는 단일 프로세서에 보통 2,500~5,000개의 ALU 포함\n",
        "- 따라서 수천 개의 곱셈과 덧셈을 동시에 실행\n",
        "\n",
        "![대체 텍스트](https://cloud.google.com/tpu/docs/images/image2.gif?hl=ko)\n",
        "\n",
        "*참고: 이 애니메이션은 개념 제시용이며 실제 프로세서 동작을 반영하지 않습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YszWkIBMxSbV",
        "colab_type": "text"
      },
      "source": [
        "### TPU 작동원리\n",
        "\n",
        "- TPU의 주 임무는 행렬 처리이므로 TPU 하드웨어 설계자는 해당 작업을 수행하는 모든 연산 단계를 미리 알고 있음\n",
        "- 따라서 수천 개의 승산기와 가산기가 서로 직접 연결되도록 배치하여 해당 연산자의 대규모 실제 행렬을 형성할 수 있음\n",
        "- 이 방식을 시스톨릭 배열 아키텍처라고 함\n",
        "- Cloud TPU v2는 128 x 128 시스톨릭 배열 2개로 16비트 부동 소수점 값용 ALU 32,768개를 단일 프로세서에 집적함\n",
        "- 아래 그림을 통해 시스톨릭 배열이 신경망 연산을 어떻게 실행하는지 살펴봄\n",
        "- 우선 TPU가 메모리의 파라미터를 승산기 및 가산기의 행렬에 로드함\n",
        "\n",
        "![대체 텍스트](https://cloud.google.com/tpu/docs/images/image4_5pfb45w.gif?hl=ko)\n",
        "\n",
        "- 그런 다음 TPU가 메모리에서 데이터를 로드함\n",
        "- 각 곱셈이 실행된 결과가 다음 승산기로 전달되는 동시에 합산이 이루어짐\n",
        "- 따라서 출력은 데이터와 매개변수 간의 모든 곱셈 결과의 합임\n",
        "- 대규모 연산 및 데이터 전달 과정 전체에서 어떠한 메모리 액세스도 필요하지 않음\n",
        "\n",
        "![대체 텍스트](https://cloud.google.com/tpu/docs/images/image1_2pdcvle.gif?hl=ko)\n",
        "\n",
        "*참고: 이 애니메이션은 개념 제시용이며 실제 프로세서 동작을 반영하지 않습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iB-KhX55vxan",
        "colab_type": "text"
      },
      "source": [
        "# 머신러닝 성능 및 벤치마크\n",
        "![대체 텍스트](https://cloud.google.com/images/products/tpu/machine-learning-performance.png?hl=ko)\n",
        "\n",
        "[출처]<https://cloud.google.com/tpu/?hl=ko>"
      ]
    }
  ]
}